<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?">
  <title>
    
      3D ResNet | 파이토치 한국 사용자 모임
    
  </title>
  <meta property="og:title" content="파이토치 한국 사용자 모임 (PyTorch Korea User Group)" />
<meta
  name="description"
  property="og:description"
  content="파이토치 한국 사용자 모임에 오신 것을 환영합니다. 딥러닝 프레임워크인 파이토치(PyTorch)를 사용하는 한국어 사용자들을 위해 문서를 번역하고 정보를 공유하고 있습니다."
/>
<meta property="og:url" content="https://pytorch.kr" />
<meta property="og:type" content="website" />
<meta
  property="og:image"
  content="https://pytorch.kr/assets/images/pytorch-kr-logo.png"
/>
<meta name="robots" content="index, follow" />

  <link rel="stylesheet" href="/assets/main.css">
  <script src="/assets/vendor/jquery.min.js"></script>
  <script src="/assets/vendor/popper.min.js"></script>
  <script src="/assets/vendor/bootstrap.min.js"></script>
  <script src="/assets/vendor/anchor.min.js"></script>
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
</head>

  <body class="hub hub-detail">
    <div class="container-fluid header-holder hub-header">
  <div class="container">
    

<div class="header-container">
  <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorchKR"></a>

  <div class="main-menu">
  <ul>
    <li class="main-menu-item ">
      <a href="/get-started">시작하기</a>
    </li>

    <li class="main-menu-item">
      <a href="https://tutorials.pytorch.kr/" target="_self">튜토리얼</a>
    </li>

    <li class="main-menu-item active">
      <a href="/hub">허브</a>
    </li>

    <li class="main-menu-item">
      <a href="https://discuss.pytorch.kr/" target="_self">커뮤니티</a>
    </li>
  </ul>
</div>

<script src="/assets/main-menu-dropdown.js"></script>


  <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
</div>

  </div>
</div>


    <div class="main-background hub-background hub-detail-background"></div>

    <div class="jumbotron jumbotron-fluid">
      <div class="container">
        <span class="detail-arrow">
          
            <a href="/hub/research-models"><</a>
          
        </span>
        <h1>
          3D ResNet
        </h1>

        <div class="row">
          <div class="col-md-4">
            <p class="detail-lead">By FAIR PyTorchVideo </p>
          </div>

          <div class="col-md-8">
            <p class="detail-lead lead-summary">Resnet Style Video classification networks pretrained on the Kinetics 400 dataset</p>
            <div class="detail-button-container">
              <a href="https://github.com/facebookresearch/pytorchvideo"><button class="btn btn-lg with-right-white-arrow detail-github-link">View on Github</button></a>
              <a href="https://colab.research.google.com/github/pytorch/pytorch.github.io/blob/master/assets/hub/facebookresearch_pytorchvideo_resnet.ipynb"><button class="btn btn-lg with-right-white-arrow detail-colab-link">Open on Google Colab</button></a>
              
                
                  <a href="https://huggingface.co/spaces/pytorch/3D_ResNet"><button class="btn btn-lg with-right-white-arrow detail-web-demo-link">Open Model Demo</button></a>
                
              
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="main-content-wrapper">
      <div class="main-content">
        <div class="container">
          <div class="row">
            <div class="col-md-4">
              <img src="/assets/images/no-image" data-image-name="no-image" class="featured-image img-fluid">
              <img src="/assets/images/no-image" data-image-name="no-image" class="featured-image img-fluid">
            </div>
            <div class="col-md-8">
              <article class="pytorch-article">
                <h3 id="example-usage">Example Usage</h3>

<h4 id="imports">Imports</h4>

<p>Load the model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># Choose the `slow_r50` model 
</span><span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">hub</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'facebookresearch/pytorchvideo'</span><span class="p">,</span> <span class="s">'slow_r50'</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<p>Import remaining functions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">urllib</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.data.encoded_video</span> <span class="kn">import</span> <span class="n">EncodedVideo</span>

<span class="kn">from</span> <span class="nn">torchvision.transforms</span> <span class="kn">import</span> <span class="n">Compose</span><span class="p">,</span> <span class="n">Lambda</span>
<span class="kn">from</span> <span class="nn">torchvision.transforms._transforms_video</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CenterCropVideo</span><span class="p">,</span>
    <span class="n">NormalizeVideo</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pytorchvideo.transforms</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ApplyTransformToKey</span><span class="p">,</span>
    <span class="n">ShortSideScale</span><span class="p">,</span>
    <span class="n">UniformTemporalSubsample</span>
<span class="p">)</span>
</code></pre></div></div>

<h4 id="setup">Setup</h4>

<p>Set the model to eval mode and move to desired device.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Set to GPU or CPU
</span><span class="n">device</span> <span class="o">=</span> <span class="s">"cpu"</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nb">eval</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<p>Download the id to label mapping for the Kinetics 400 dataset on which the torch hub models were trained. This will be used to get the category label names from the predicted class ids.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">json_url</span> <span class="o">=</span> <span class="s">"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json"</span>
<span class="n">json_filename</span> <span class="o">=</span> <span class="s">"kinetics_classnames.json"</span>
<span class="k">try</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">URLopener</span><span class="p">().</span><span class="n">retrieve</span><span class="p">(</span><span class="n">json_url</span><span class="p">,</span> <span class="n">json_filename</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">json_url</span><span class="p">,</span> <span class="n">json_filename</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">json_filename</span><span class="p">,</span> <span class="s">"r"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">kinetics_classnames</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

<span class="c1"># Create an id to label name mapping
</span><span class="n">kinetics_id_to_classname</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kinetics_classnames</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">kinetics_id_to_classname</span><span class="p">[</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">).</span><span class="n">replace</span><span class="p">(</span><span class="s">'"'</span><span class="p">,</span> <span class="s">""</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="define-input-transform">Define input transform</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">side_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">mean</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">]</span>
<span class="n">std</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
<span class="n">crop_size</span> <span class="o">=</span> <span class="mi">256</span>
<span class="n">num_frames</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">sampling_rate</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">frames_per_second</span> <span class="o">=</span> <span class="mi">30</span>

<span class="c1"># Note that this transform is specific to the slow_R50 model.
</span><span class="n">transform</span> <span class="o">=</span>  <span class="n">ApplyTransformToKey</span><span class="p">(</span>
    <span class="n">key</span><span class="o">=</span><span class="s">"video"</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">UniformTemporalSubsample</span><span class="p">(</span><span class="n">num_frames</span><span class="p">),</span>
            <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">/</span><span class="mf">255.0</span><span class="p">),</span>
            <span class="n">NormalizeVideo</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">),</span>
            <span class="n">ShortSideScale</span><span class="p">(</span>
                <span class="n">size</span><span class="o">=</span><span class="n">side_size</span>
            <span class="p">),</span>
            <span class="n">CenterCropVideo</span><span class="p">(</span><span class="n">crop_size</span><span class="o">=</span><span class="p">(</span><span class="n">crop_size</span><span class="p">,</span> <span class="n">crop_size</span><span class="p">))</span>
        <span class="p">]</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="c1"># The duration of the input clip is also specific to the model.
</span><span class="n">clip_duration</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_frames</span> <span class="o">*</span> <span class="n">sampling_rate</span><span class="p">)</span><span class="o">/</span><span class="n">frames_per_second</span>
</code></pre></div></div>

<h4 id="run-inference">Run Inference</h4>

<p>Download an example video.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">url_link</span> <span class="o">=</span> <span class="s">"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4"</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s">'archery.mp4'</span>
<span class="k">try</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">URLopener</span><span class="p">().</span><span class="n">retrieve</span><span class="p">(</span><span class="n">url_link</span><span class="p">,</span> <span class="n">video_path</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span> <span class="n">urllib</span><span class="p">.</span><span class="n">request</span><span class="p">.</span><span class="n">urlretrieve</span><span class="p">(</span><span class="n">url_link</span><span class="p">,</span> <span class="n">video_path</span><span class="p">)</span>
</code></pre></div></div>

<p>Load the video and transform it to the input format required by the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Select the duration of the clip to load by specifying the start and end duration
# The start_sec should correspond to where the action occurs in the video
</span><span class="n">start_sec</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">end_sec</span> <span class="o">=</span> <span class="n">start_sec</span> <span class="o">+</span> <span class="n">clip_duration</span>

<span class="c1"># Initialize an EncodedVideo helper class and load the video
</span><span class="n">video</span> <span class="o">=</span> <span class="n">EncodedVideo</span><span class="p">.</span><span class="n">from_path</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>

<span class="c1"># Load the desired clip
</span><span class="n">video_data</span> <span class="o">=</span> <span class="n">video</span><span class="p">.</span><span class="n">get_clip</span><span class="p">(</span><span class="n">start_sec</span><span class="o">=</span><span class="n">start_sec</span><span class="p">,</span> <span class="n">end_sec</span><span class="o">=</span><span class="n">end_sec</span><span class="p">)</span>

<span class="c1"># Apply a transform to normalize the video input
</span><span class="n">video_data</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">video_data</span><span class="p">)</span>

<span class="c1"># Move the inputs to the desired device
</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">video_data</span><span class="p">[</span><span class="s">"video"</span><span class="p">]</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</code></pre></div></div>

<h4 id="get-predictions">Get Predictions</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass the input clip through the model
</span><span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="p">...])</span>

<span class="c1"># Get the predicted classes
</span><span class="n">post_act</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">post_act</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
<span class="n">pred_classes</span> <span class="o">=</span> <span class="n">preds</span><span class="p">.</span><span class="n">topk</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">).</span><span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Map the predicted classes to the label names
</span><span class="n">pred_class_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">kinetics_id_to_classname</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">pred_classes</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Top 5 predicted labels: %s"</span> <span class="o">%</span> <span class="s">", "</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">pred_class_names</span><span class="p">))</span>
</code></pre></div></div>

<h3 id="model-description">Model Description</h3>
<p>The model architecture is based on [1] with pretrained weights using the 8x8 setting
on the Kinetics dataset. 
| arch | depth | frame length x sample rate | top 1 | top 5 | Flops (G) | Params (M) |
| ————— | ———– | ———– | ———– | ———– | ———– |  ———– | ———– |
| Slow     | R50   | 8x8                        | 74.58 | 91.63 | 54.52     | 32.45     |</p>

<h3 id="references">References</h3>
<p>[1] Christoph Feichtenhofer et al, “SlowFast Networks for Video Recognition”
https://arxiv.org/pdf/1812.03982.pdf</p>

                <a href="https://github.com/PyTorchKorea/hub-kr/issues"><button class="btn btn-lg hub-feedback-button hub-flag">Not Working?</button></a>
              </article>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container-fluid docs-tutorials-resources">
  <div class="container">
    <div class="row">
      <div class="col-md-4 text-center">
        <h2>PyTorchKorea @ GitHub</h2>
        <p>파이토치 한국 사용자 모임을 GitHub에서 만나보세요.</p>
        <a class="with-right-arrow" href="https://github.com/PyTorchKorea">GitHub로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>한국어 튜토리얼</h2>
        <p>한국어로 번역 중인 파이토치 튜토리얼을 만나보세요.</p>
        <a class="with-right-arrow" href="https://tutorials.pytorch.kr/">튜토리얼로 이동</a>
      </div>

      <div class="col-md-4 text-center">
        <h2>커뮤니티</h2>
        <p>다른 사용자들과 의견을 나누고, 도와주세요!</p>
        <a class="with-right-arrow" href="https://discuss.pytorch.kr/">커뮤니티로 이동</a>
      </div>
    </div>
  </div>
</div>

<footer class="site-footer">
  <div class="container footer-container">
    <div class="footer-logo-wrapper">
      <a href="https://pytorch.kr" class="footer-logo"></a>
    </div>

    <div class="footer-links-wrapper">
      <div class="footer-links-col">
        <ul>
          <li class="list-title"><a href="">파이토치 한국 사용자 모임</a></li>
          <li><a href="/about">사용자 모임 소개</a></li>
          <li><a href="/about/contributors">기여해주신 분들</a></li>
          <li><a href="/resources">리소스</a></li>
          <li><a href="/coc">행동 강령</a></li>
        </ul>
      </div>
    </div>

    <div class="trademark-disclaimer">
      <ul>
        <li>파이토치 한국 사용자 모임은 사용자들이 함께 모여 만들어가는 독립적인 커뮤니티로, 모든 활동은 Facebook과 관련이 없습니다. (We're independent user community. All activities are not related to Facebook.)</li>
        <li><a href="https://pytorch.kr/coc">행동 강령</a>을 지켜주세요. PyTorch, PyTorch 로고 및 모든 관련 표기는 Facebook, Inc의 상표입니다. (Please follow <a href="https://pytorch.kr/coc">code of conduct</a>. PyTorch, the PyTorch logo and all related marks are trademarks of Facebook, Inc.)</li>
      </ul>
    </div>
  </div>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LEHG248408"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-LEHG248408');   // GA4
  gtag('config', 'UA-156349638-1'); // UA
</script>

</footer>

<div class="mobile-main-menu">
  <div class="container-fluid">
    <div class="container">
      <div class="mobile-main-menu-header-container">
        <a class="header-logo" href="https://pytorch.kr" aria-label="PyTorch"></a>
        <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
      </div>
    </div>
  </div>

  <div class="mobile-main-menu-links-container">

    <div class="main-menu">
      <ul>

        <li class="main-menu-item ">
          <a href="/get-started">시작하기</a>
        </li>

        <li class="main-menu-item">
          <a href="https://tutorials.pytorch.kr/">튜토리얼</a>
        </li>

        <li class="main-menu-item">
          <a href="/hub">허브</a>
        </li>

        <li class="main-menu-item">
          <a href="https://discuss.pytorch.kr/">커뮤니티</a>
        </li>

      </ul>
    </div>

  </div>
</div>


<script src="/assets/mobile-menu.js"></script>
<script src="/assets/scroll-to-anchor.js"></script>
<script src="/assets/external-links-new-tab.js"></script>
<!-- 
  <script src="/assets/search-bar.js"></script>

<script src="/assets/cookie-banner.js"></script> -->

<script type="text/javascript">
  mobileMenu.bind();
  anchors.add('.pytorch-article h2, .pytorch-article h3, .pytorch-article h4, .pytorch-article h5');

  // Add class to links that have code blocks, since we cannot create links in code blocks
  $("a code.highlighter-rouge").each(function(e) {
    $(this).closest("a").addClass("has-code");
  });

  scrollToAnchor.bind();

  var hasStaticHeader = $(".blog-header, .blog-detail-header, .resources-header, .get-started-header, .features-header, .ecosystem-header, .hub-header, .mobile-header, .coc-header").length > 0;

  if (!hasStaticHeader) {
    $(window).on("scroll", function() {
      var top = $(this).scrollTop();
      var fullPosition = $(".main-background").height() - $(".header-holder").height();

      if (top <= 40) {
        $(".header-holder").css({"backgroundColor": "rgba(0, 0, 0, 0.165)"});
      } else if (top >= fullPosition) {
        $(".header-holder").css({"backgroundColor": "#000000"});
      } else {
        var bgColor = "rgba(0, 0, 0, " + top / fullPosition + ")";
        $(".header-holder").css({"backgroundColor": bgColor});
      }
    });
  }
</script>

<script src="/assets/track-events.js"></script>
<script>trackEvents.bind();</script>


  </body>
</html>

<script src="/assets/hub-detail.js"></script>
